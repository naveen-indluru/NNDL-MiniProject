{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9-Dm2jEP4lw"
   },
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgvkRJ8sUftf",
    "outputId": "941d21ac-b2b6-4695-e0bd-404ab442b373"
   },
   "outputs": [],
   "source": [
    "# !pip install torchmetrics\n",
    "# !pip install tqdm\n",
    "# !pip install terminaltables\n",
    "# !pip install autocast\n",
    "# # !pip install ch\n",
    "# !pip install pytorch-lightning\n",
    "# !pip install hydra-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ql9qDWPkSbnL"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torchvision import models\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "# from fastargs import get_current_config\n",
    "# from fastargs.decorators import param\n",
    "# from fastargs import Param, Section\n",
    "# from fastargs.validation import And, OneOf\n",
    "\n",
    "# from ffcv.pipeline.operation import Operation\n",
    "# from ffcv.loader import Loader, OrderOption\n",
    "# from ffcv.transforms import ToTensor, ToDevice, Squeeze, NormalizeImage, \\\n",
    "#     RandomHorizontalFlip, ToTorchImage\n",
    "# from ffcv.fields.rgb_image import CenterCropRGBImageDecoder, \\\n",
    "#     RandomResizedCropRGBImageDecoder\n",
    "# from ffcv.fields.basics import IntDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d83A8zkh8ZuO"
   },
   "source": [
    "MATRYOKSHA FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-YcITzBXSkCT"
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Loss function for Matryoshka Representation Learning\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Matryoshka_CE_Loss(nn.Module):\n",
    "    def __init__(self, relative_importance=None, **kwargs):\n",
    "        super(Matryoshka_CE_Loss, self).__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss(**kwargs)\n",
    "        self.relative_importance = relative_importance\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        losses = torch.stack([self.criterion(output_i, target) for output_i in output])\n",
    "        rel_importance = torch.ones_like(losses) if self.relative_importance is None else torch.tensor(self.relative_importance)\n",
    "        weighted_losses = rel_importance * losses\n",
    "        return weighted_losses.sum()\n",
    "\n",
    "class MRL_Linear_Layer(nn.Module):\n",
    "    def __init__(self, nesting_list, num_classes=1000, efficient=False, **kwargs):\n",
    "        super(MRL_Linear_Layer, self).__init__()\n",
    "        self.nesting_list = nesting_list\n",
    "        self.num_classes = num_classes\n",
    "        self.efficient = efficient\n",
    "        if self.efficient:\n",
    "            setattr(self, f'nesting_classifier_{0}', nn.Linear(nesting_list[-1], self.num_classes, **kwargs))\n",
    "        else:\n",
    "            for i, num_feat in enumerate(self.nesting_list):\n",
    "                setattr(self, f'nesting_classifier_{i}', nn.Linear(num_feat, self.num_classes, **kwargs))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.efficient:\n",
    "            self.nesting_classifier_0.reset_parameters()\n",
    "        else:\n",
    "            for i in range(len(self.nesting_list)):\n",
    "                getattr(self, f'nesting_classifier_{i}').reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        nesting_logits = ()\n",
    "        for i, num_feat in enumerate(self.nesting_list):\n",
    "            if self.efficient:\n",
    "                nesting_logits += (getattr(self, f'nesting_classifier_{0}')(x[:, :num_feat]),)\n",
    "            else:\n",
    "                nesting_logits += (getattr(self, f'nesting_classifier_{i}')(x[:, :num_feat]),)\n",
    "        return nesting_logits\n",
    "\n",
    "class FixedFeatureLayer(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, **kwargs):\n",
    "        super(FixedFeatureLayer, self).__init__(in_features, out_features, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not (self.bias is None):\n",
    "            out = torch.matmul(x[:, :self.in_features], self.weight.t()) + self.bias\n",
    "        else:\n",
    "            out = torch.matmul(x[:, :self.in_features], self.weight.t())\n",
    "        return out\n",
    "\n",
    "nesting_list = [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "fc_layer = MRL_Linear_Layer(nesting_list, num_classes=1000, efficient=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O22atDzr53jw"
   },
   "source": [
    "INPUTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qet1axJU54jV"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "weights = ResNet18_Weights.DEFAULT  # Define weights based on model\n",
    "\n",
    "'''\n",
    "This code is directly taken from FFCV-Imagenet https://github.com/libffcv/ffcv-imagenet\n",
    "and modified for MRL purpose.\n",
    "'''\n",
    "sys.path.append(\"../\") # adding root folder to the path\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.profiler.emit_nvtx(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "\n",
    "config_file = 'rn50_configs/rn50_40_epochs.yaml'\n",
    "model_fixed_feature = 2048\n",
    "# train_dataset = os.environ['WRITE_DIR'] + '/train_500_0.50_90.ffcv'\n",
    "# val_dataset = os.environ['WRITE_DIR'] + '/val_500_uncompressed.ffcv'\n",
    "num_workers = 12\n",
    "in_memory = True\n",
    "logging_folder = 'trainlogs'\n",
    "log_level = 0\n",
    "world_size = 2\n",
    "distributed = False\n",
    "learning_rate = 0.425\n",
    "\n",
    "arch='resnet18'\n",
    "pretrained=0\n",
    "efficient=0\n",
    "mrl=0\n",
    "nesting_start=3\n",
    "fixed_feature=2048\n",
    "\n",
    "\n",
    "min_res=160\n",
    "max_res=160\n",
    "end_ramp=0\n",
    "start_ramp=0\n",
    "\n",
    "\n",
    "step_ratio=0.1\n",
    "step_length=30\n",
    "lr_schedule_type='cyclic'\n",
    "lr=0.5\n",
    "lr_peak_epoch=2\n",
    "\n",
    "\n",
    "\n",
    "folder=logging_folder\n",
    "\n",
    "\n",
    "batch_size=512\n",
    "resolution=224\n",
    "lr_tta=1\n",
    "\n",
    "\n",
    "eval_only=0\n",
    "path=None\n",
    "batch_size=512\n",
    "optimizer='sgd'\n",
    "momentum=0.9\n",
    "weight_decay=4e-5\n",
    "epochs=15\n",
    "label_smoothing=0.1\n",
    "distributed=0\n",
    "use_blurpool=0\n",
    "\n",
    "\n",
    "\n",
    "address='localhost'\n",
    "port=12355\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIKTNuKpSgQ8"
   },
   "source": [
    "DATASET LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWzk88u9Sfc_",
    "outputId": "c98e5b70-28d3-4731-bb4f-c4ec16cf2a0c"
   },
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, label_transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.label_transform = label_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx].transpose((1, 2, 0))  # Transpose to (32, 32, 3)\n",
    "        label = self.labels[idx]\n",
    "        image = Image.fromarray(image.astype('uint8'))  # Convert to PIL Image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.label_transform:\n",
    "            label = self.label_transform(label)\n",
    "        return image, label\n",
    "\n",
    "def load_cifar10_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        batch = pickle.load(fo, encoding='latin1')\n",
    "    data = batch['data']\n",
    "    labels = batch['labels']\n",
    "    data = data.reshape(-1, 3, 32, 32)  # Reshape data\n",
    "    return data, labels\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    for i in range(1, 6):\n",
    "        batch_data, batch_labels = load_cifar10_batch(os.path.join(data_dir, f'data_batch_{1}'))\n",
    "        train_data.append(batch_data)\n",
    "        train_labels.extend(batch_labels)\n",
    "    train_data = np.vstack(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_data, test_labels = load_cifar10_batch(os.path.join(data_dir, 'test_batch'))\n",
    "    test_data = test_data.reshape(-1, 3, 32, 32)\n",
    "    test_labels = np.array(test_labels)\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "# data_dir = 'cifar/'  # Modify with actual path\n",
    "data_dir = 'data/cifar-10-batches-py/'\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10_data(data_dir)\n",
    "\n",
    "this_device = torch.device('cuda')\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10), #newly added\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "def label_transform(label):\n",
    "    # Transform labels to tensor\n",
    "    # return torch.tensor(label, dtype=torch.long).to(this_device, non_blocking=True)\n",
    "    return torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_dataset = CIFAR10Dataset(train_data, train_labels, transform=transform_train, label_transform=label_transform)\n",
    "test_dataset = CIFAR10Dataset(test_data, test_labels, transform=transform_test, label_transform=label_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iopy55xoTX6G"
   },
   "source": [
    "HELPER FNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0E8qlNRlTa__"
   },
   "outputs": [],
   "source": [
    "CIFAR_MEAN = np.array([0.485, 0.456, 0.406]) * 255\n",
    "CIFAR_STD = np.array([0.229, 0.224, 0.225]) * 255\n",
    "DEFAULT_CROP_RATIO = 224/256\n",
    "\n",
    "def get_step_lr(epoch, lr=lr, step_ratio=step_ratio, step_length=step_length, epochs=epochs):\n",
    "    if epoch >= epochs:\n",
    "        return 0\n",
    "\n",
    "    num_steps = epoch // step_length\n",
    "    return step_ratio**num_steps * lr\n",
    "\n",
    "def get_constant_lr(epoch, lr=lr):\n",
    "    return lr\n",
    "\n",
    "def get_cyclic_lr(epoch, lr=lr, epochs=epochs, lr_peak_epoch=lr_peak_epoch):\n",
    "    xs = [0, lr_peak_epoch, epochs]\n",
    "    ys = [1e-4 * lr, lr, 0]\n",
    "    return np.interp([epoch], xs, ys)[0]\n",
    "\n",
    "class BlurPoolConv2d(torch.nn.Module):\n",
    "    def __init__(self, conv):\n",
    "        super().__init__()\n",
    "        default_filter = torch.tensor([[[[1, 2, 1], [2, 4, 2], [1, 2, 1]]]]) / 16.0\n",
    "        filt = default_filter.repeat(conv.in_channels, 1, 1, 1)\n",
    "        self.conv = conv\n",
    "        self.register_buffer('blur_filter', filt)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blurred = F.conv2d(x, self.blur_filter, stride=1, padding=(1, 1),\n",
    "                           groups=self.conv.in_channels, bias=None)\n",
    "        return self.conv.forward(blurred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MjO82k2Tlfh"
   },
   "source": [
    "CIFARTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dtvWwTZrSZbZ"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "weights = ResNet18_Weights.DEFAULT  # Define weights based on model\n",
    "\n",
    "class CIFARTrainer:\n",
    "    def __init__(self, gpu, train_loader = train_loader, val_loader=val_loader,distributed=distributed, efficient=efficient, mrl=mrl, nesting_start=nesting_start, fixed_feature=fixed_feature,\n",
    "                 this_device=  this_device):\n",
    "        # self.all_params = get_current_config();\n",
    "        self.gpu = gpu\n",
    "        self.efficient = efficient\n",
    "        self.nesting = (self.efficient or mrl)\n",
    "        self.nesting_start = nesting_start\n",
    "        self.nesting_list = [2**i for i in range(self.nesting_start, 12)] if self.nesting else None\n",
    "        self.fixed_feature=fixed_feature\n",
    "        self.uid = str(uuid4())\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "        self.this_device = this_device\n",
    "\n",
    "\n",
    "        if distributed:\n",
    "            self.setup_distributed()\n",
    "\n",
    "        self.model, self.scaler = self.create_model_and_scaler()\n",
    "        # self.model.cuda().half()\n",
    "        self.create_optimizer()\n",
    "        self.initialize_logger()\n",
    "\n",
    "\n",
    "    def setup_distributed(self, address=address, port=port, world_size=world_size):\n",
    "        os.environ['MASTER_ADDR'] = address\n",
    "        os.environ['MASTER_PORT'] = port\n",
    "\n",
    "        dist.init_process_group(\"nccl\", rank=self.gpu, world_size=world_size)\n",
    "        torch.cuda.set_device(self.gpu)\n",
    "\n",
    "    def cleanup_distributed(self):\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "    def get_lr(self, epoch, lr_schedule_type=lr_schedule_type):\n",
    "        lr_schedules = {\n",
    "            'cyclic': get_cyclic_lr,\n",
    "            'step': get_step_lr,\n",
    "            'constant': get_constant_lr\n",
    "        }\n",
    "\n",
    "        return lr_schedules[lr_schedule_type](epoch)\n",
    "\n",
    "    # resolution tools\n",
    "    def get_resolution(self, epoch, min_res=min_res, max_res=max_res, end_ramp=end_ramp, start_ramp=start_ramp):\n",
    "        assert min_res <= max_res\n",
    "\n",
    "        if epoch <= start_ramp:\n",
    "            return min_res\n",
    "\n",
    "        if epoch >= end_ramp:\n",
    "            return max_res\n",
    "\n",
    "        # otherwise, linearly interpolate to the nearest multiple of 32\n",
    "        interp = np.interp([epoch], [start_ramp, end_ramp], [min_res, max_res])\n",
    "        final_res = int(np.round(interp[0] / 32)) * 32\n",
    "        return final_res\n",
    "\n",
    "    def create_optimizer(self, momentum=momentum, optimizer=optimizer, weight_decay=weight_decay,\n",
    "                         label_smoothing=label_smoothing):\n",
    "        assert optimizer == 'sgd'\n",
    "\n",
    "        # Only do weight decay on non-batchnorm parameters\n",
    "        all_params = list(self.model.named_parameters())\n",
    "        bn_params = [v for k, v in all_params if ('bn' in k)]\n",
    "        other_params = [v for k, v in all_params if not ('bn' in k)]\n",
    "        param_groups = [{\n",
    "            'params': bn_params,\n",
    "            'weight_decay': 0.\n",
    "        }, {\n",
    "            'params': other_params,\n",
    "            'weight_decay': weight_decay\n",
    "        }]\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(param_groups, lr=1, momentum=momentum)\n",
    "        # Adding Nesting Case....\n",
    "        if self.nesting:\n",
    "            self.loss = Matryoshka_CE_Loss(label_smoothing=label_smoothing)\n",
    "        else:\n",
    "            self.loss = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "    def train(self, epochs=epochs, log_level=log_level):\n",
    "        for epoch in range(epochs):\n",
    "            print(\"epoch no. \", epoch)\n",
    "            # res = self.get_resolution(epoch)\n",
    "            # self.decoder.output_size = (res, res)\n",
    "            train_loss = self.train_loop(epoch)\n",
    "\n",
    "            if log_level > 0:\n",
    "                extra_dict = {\n",
    "                    'train_loss': train_loss,\n",
    "                    'epoch': epoch\n",
    "                }\n",
    "\n",
    "                self.eval_and_log(extra_dict)\n",
    "\n",
    "        # self.eval_and_log({'epoch':epoch})\n",
    "        if self.gpu == 0:\n",
    "            torch.save(self.model.state_dict(), self.log_folder / 'final_weights.pt')\n",
    "\n",
    "    def eval_and_log(self, extra_dict={}):\n",
    "        start_val = time.time()\n",
    "        if self.nesting:\n",
    "            stats = self.val_loop_nesting()\n",
    "        else:\n",
    "            stats = self.val_loop()\n",
    "        val_time = time.time() - start_val\n",
    "\n",
    "        if self.gpu == 0:\n",
    "            d = {\n",
    "                'current_lr': self.optimizer.param_groups[0]['lr'], 'val_time': val_time\n",
    "            }\n",
    "            for k in stats.keys():\n",
    "                if k=='loss':\n",
    "                    continue\n",
    "                else:\n",
    "                    d[k]=stats[k]\n",
    "\n",
    "            self.log(dict(d, **extra_dict))\n",
    "\n",
    "        return stats\n",
    "\n",
    "    def create_model_and_scaler(self, arch=arch, weights=weights, distributed=distributed, use_blurpool=use_blurpool):\n",
    "        '''\n",
    "        Nesting Start is just the log_2 {smallest dim} unit. In our work we used powers of two, however this part can be changed easily.\n",
    "        If we do not want to use MRL, we just keep both the efficient and mrl flags to 0\n",
    "        If we want a fixed feature baseline, then we just change fixed_feature={Rep. Size of your choice}\n",
    "\n",
    "        NOTE: FFCV Uses Blurpool.\n",
    "        '''\n",
    "\n",
    "        scaler = GradScaler()\n",
    "        model = getattr(models, arch)(weights=weights)\n",
    "\n",
    "        if self.nesting:\n",
    "            ff= \"MRL-E\" if self.efficient else \"MRL\"\n",
    "            print(f\"Creating classification layer of type :\\t {ff}\")\n",
    "            model.fc = MRL_Linear_Layer(self.nesting_list, num_classes=1000, efficient=self.efficient)\n",
    "        elif self.fixed_feature != 2048:\n",
    "            print(\"Using Fixed Features.... \")\n",
    "            model.fc =  FixedFeatureLayer(self.fixed_feature, 1000)\n",
    "\n",
    "        def apply_blurpool(mod: torch.nn.Module):\n",
    "            for (name, child) in mod.named_children():\n",
    "                if isinstance(child, torch.nn.Conv2d) and (np.max(child.stride) > 1 and child.in_channels >= 16):\n",
    "                    setattr(mod, name, BlurPoolConv2d(child))\n",
    "                else: apply_blurpool(child)\n",
    "        if use_blurpool: apply_blurpool(model)\n",
    "\n",
    "        model = model.to(memory_format=torch.channels_last)\n",
    "        model = model.to(self.gpu)\n",
    "\n",
    "        if distributed:\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[self.gpu])\n",
    "\n",
    "        return model, scaler\n",
    "\n",
    "    def train_loop(self, epoch, log_level=log_level):\n",
    "        model = self.model\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        lr_start, lr_end = self.get_lr(epoch), self.get_lr(epoch + 1)\n",
    "        iters = len(self.train_loader)\n",
    "        lrs = np.interp(np.arange(iters), [0, iters], [lr_start, lr_end])\n",
    "\n",
    "        iterator = tqdm(self.train_loader)\n",
    "        for ix, (images, target) in enumerate(iterator):\n",
    "            images = images.to(self.this_device, non_blocking=True)\n",
    "            target = target.to(self.this_device, non_blocking=True)\n",
    "            ### Training start\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = lrs[ix]\n",
    "\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                # images = images.cuda().half()\n",
    "\n",
    "                output = self.model(images)\n",
    "                loss_train = self.loss(output, target)\n",
    "\n",
    "            self.scaler.scale(loss_train).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            ### Training end\n",
    "\n",
    "            ### Logging start\n",
    "            if log_level > 0:\n",
    "                losses.append(loss_train.detach())\n",
    "\n",
    "                group_lrs = []\n",
    "                for _, group in enumerate(self.optimizer.param_groups):\n",
    "                    group_lrs.append(f'{group[\"lr\"]:.3f}')\n",
    "\n",
    "                names = ['ep', 'iter', 'shape', 'lrs']\n",
    "                values = [epoch, ix, tuple(images.shape), group_lrs]\n",
    "                if log_level > 1:\n",
    "                    names += ['loss']\n",
    "                    values += [f'{loss_train.item():.3f}']\n",
    "\n",
    "                msg = ', '.join(f'{n}={v}' for n, v in zip(names, values))\n",
    "                iterator.set_description(msg)\n",
    "            ### Logging end\n",
    "\n",
    "        if log_level > 0:\n",
    "            loss = torch.stack(losses).mean().cpu()\n",
    "            assert not torch.isnan(loss), 'Loss is NaN!'\n",
    "            return loss.item()\n",
    "\n",
    "    def val_loop(self, lr_tta=lr_tta):\n",
    "        model = self.model\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                for images, target in tqdm(self.val_loader):\n",
    "                    images = images.to(self.this_device, non_blocking=True)\n",
    "                    target = target.to(self.this_device, non_blocking=True)\n",
    "                    images = images.cuda().half()\n",
    "                    output = self.model(images)\n",
    "                    if lr_tta:\n",
    "                        output += self.model(torch.flip(images, dims=[3]))\n",
    "\n",
    "                    for k in ['top_1', 'top_5']:\n",
    "                        self.val_meters[k](output, target)\n",
    "\n",
    "                    loss_val = self.loss(output, target)\n",
    "                    self.val_meters['loss'](loss_val)\n",
    "\n",
    "        stats = {k: m.compute().item() for k, m in self.val_meters.items()}\n",
    "        [meter.reset() for meter in self.val_meters.values()]\n",
    "        return stats\n",
    "\n",
    "\n",
    "    def val_loop_nesting(self, lr_tta=lr_tta):\n",
    "        '''\n",
    "        Since Nested Layers will give a tuple of logits, we have a different subroutine for validation.\n",
    "        '''\n",
    "\n",
    "        model = self.model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                for images, target in tqdm(self.val_loader):\n",
    "                    images = images.to(self.this_device, non_blocking=True)\n",
    "                    target = target.to(self.this_device, non_blocking=True)\n",
    "                    output = self.model(images); output=torch.stack(output, dim=0)\n",
    "\n",
    "                    if lr_tta:\n",
    "                        output +=torch.stack(self.model(torch.flip(images, dims=[3])), dim=0) # Just one augmentation.\n",
    "\n",
    "                    # Logging the accuracies top1/5 for each of nesting...\n",
    "                    for i in range(len(self.nesting_list)):\n",
    "                        s = \"top_1_{}\".format(self.nesting_list[i])\n",
    "                        self.val_meters[s](output[i], target)\n",
    "                        s = \"top_5_{}\".format(self.nesting_list[i])\n",
    "                        self.val_meters[s](output[i], target)\n",
    "\n",
    "                    loss_val = self.loss(output, target)\n",
    "                    self.val_meters['loss'](loss_val)\n",
    "\n",
    "        stats = {k: m.compute().item() for k, m in self.val_meters.items()}\n",
    "        [meter.reset() for meter in self.val_meters.values()]\n",
    "        return stats\n",
    "\n",
    "\n",
    "    def initialize_logger(self, folder=folder):\n",
    "        if self.nesting:\n",
    "            self.val_meters={}\n",
    "            for i in self.nesting_list:\n",
    "                self.val_meters['top_1_{}'.format(i)] = torchmetrics.Accuracy(compute_on_step=False).to(self.gpu)\n",
    "\n",
    "            for i in self.nesting_list:\n",
    "                self.val_meters['top_5_{}'.format(i)] = torchmetrics.Accuracy(compute_on_step=False, top_k=5).to(self.gpu)\n",
    "\n",
    "            self.val_meters['loss'] = MeanScalarMetric(compute_on_step=False).to(self.gpu)\n",
    "\n",
    "        else:\n",
    "            self.val_meters = {\n",
    "                'top_1': torchmetrics.Accuracy(task='multiclass', num_classes=10).to(self.gpu),\n",
    "                'top_5': torchmetrics.Accuracy(task='multiclass', top_k=5, num_classes=10).to(self.gpu),\n",
    "                'loss': MeanScalarMetric().to(self.gpu)\n",
    "            }\n",
    "\n",
    "        if self.gpu == 0:\n",
    "            folder = (Path(folder) / str(self.uid)).absolute()\n",
    "            folder.mkdir(parents=True)\n",
    "\n",
    "            self.log_folder = folder\n",
    "            self.start_time = time.time()\n",
    "\n",
    "            print(f'=> Logging in {self.log_folder}')\n",
    "            # params = {\n",
    "            #     '.'.join(k): self.all_params[k] for k in self.all_params.entries.keys()\n",
    "            # }\n",
    "\n",
    "            # with open(folder / 'params.json', 'w+') as handle:\n",
    "            #     json.dump(params, handle)\n",
    "\n",
    "    def log(self, content):\n",
    "        print(f'=> Log: {content}')\n",
    "        if self.gpu != 0: return\n",
    "        cur_time = time.time()\n",
    "        with open(self.log_folder / 'log', 'a+') as fd:\n",
    "            fd.write(json.dumps({\n",
    "                'timestamp': cur_time,\n",
    "                'relative_time': cur_time - self.start_time,\n",
    "                **content\n",
    "            }) + '\\n')\n",
    "            fd.flush()\n",
    "\n",
    "    @classmethod\n",
    "    def launch_from_args(cls, distributed=False, world_size=2, eval_only=0):\n",
    "        if distributed:\n",
    "            torch.multiprocessing.spawn(cls._exec_wrapper, nprocs=world_size, join=True)\n",
    "        else:\n",
    "            cls.exec(0, distributed, eval_only)\n",
    "\n",
    "    @classmethod\n",
    "    def _exec_wrapper(cls, *args, **kwargs):\n",
    "        make_config(quiet=True)\n",
    "        cls.exec(*args, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def exec(cls, gpu, distributed=distributed, eval_only=eval_only, path=None):\n",
    "        trainer = cls(gpu=gpu)\n",
    "        if eval_only:\n",
    "            print(\"Loading Model.....\"); ckpt = torch.load(path, map_location=\"cuda:{}\".format(gpu))\n",
    "            trainer.model.load_state_dict(ckpt); print(\"Loading Complete!\")\n",
    "            trainer.eval_and_log()\n",
    "        else:\n",
    "            trainer.train()\n",
    "\n",
    "        if distributed:\n",
    "            trainer.cleanup_distributed()\n",
    "\n",
    "# Utils\n",
    "class MeanScalarMetric(torchmetrics.Metric):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.add_state('sum', default=torch.tensor(0.), dist_reduce_fx='sum')\n",
    "        self.add_state('count', default=torch.tensor(0), dist_reduce_fx='sum')\n",
    "\n",
    "    def update(self, sample: torch.Tensor):\n",
    "        self.sum += sample.sum()\n",
    "        self.count += sample.numel()\n",
    "\n",
    "    def compute(self):\n",
    "        return self.sum.float() / self.count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uo6HjBlsT9KA",
    "outputId": "b6047cc2-5a24-458f-81e3-b9a559b2038c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Logging in D:\\Fall2024\\NeuralNetworkDeepLearning\\Project\\MiniProject\\NNDL_MRL_MiniProject\\trainlogs\\42edc371-7f56-4431-bece-7c7b4df3d60f\n",
      "epoch no.  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:17<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 24.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 24.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 23.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 23.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 24.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 24.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 24.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 24.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running\n",
    "# def make_config(quiet=False):\n",
    "#     config = get_current_config()\n",
    "#     parser = ArgumentParser(description='Fast CIFAR training')\n",
    "#     config.validate(mode='stderr')\n",
    "#     if not quiet:\n",
    "#         config.summary()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # make_config()\n",
    "    CIFARTrainer.launch_from_args(distributed, world_size, eval_only)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
